{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "157de123",
   "metadata": {},
   "source": [
    "# 08 Deep Learning Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fe7dccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed generators\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed()\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b90837",
   "metadata": {},
   "source": [
    "## Class for Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "46394717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class HairDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform=transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(self.data_dir))\n",
    "        self.class_to_idx = {cls:i for i,cls in enumerate(self.classes)}\n",
    "\n",
    "        for label in self.classes:\n",
    "            label_dir = os.path.join(self.data_dir, label)\n",
    "            for img in os.listdir(label_dir):\n",
    "                img = os.path.join(self.data_dir, label, img)\n",
    "                self.image_paths.append(img)\n",
    "                self.labels.append(self.class_to_idx[label])\n",
    "\n",
    "    def show_paths(self):\n",
    "        print(self.image_paths)\n",
    "\n",
    "    def show_labels(self):\n",
    "        print(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be666a90",
   "metadata": {},
   "source": [
    "## Simple Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f49ed1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# make sure the initial input is of size (200, 200, 3)\n",
    "input_size=200\n",
    "\n",
    "# imagenet normalization values\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Simple transforms: (1) Resize the input (2) convert to a tensor (3) Normalize the image\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(input_size, input_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(input_size, input_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca21607",
   "metadata": {},
   "source": [
    "## Create DataLoaders\n",
    "- load the train and validation datasets\n",
    "- use the `DataLoader` to setup the batch size, and shuffle images for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "00b61713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = HairDataset(data_dir=\"../datasets/08-homework_dataset/train/\",\n",
    "                       transform=train_transforms\n",
    "                       )\n",
    "\n",
    "val_ds = HairDataset(data_dir=\"../datasets/08-homework_dataset/test/\",\n",
    "                     transform=val_transforms\n",
    "                     )\n",
    "\n",
    "batch_size=20\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dc70ca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# num classes will be changed to 32\n",
    "class HairClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3), padding=0, stride=1)\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense_1 = nn.Linear(313632, 64)\n",
    "        self.dense_2 = nn.Linear(64, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pooling(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense_2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c1fcc9",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae42a05",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Which loss function you will use?\n",
    "\n",
    "__A: nn.BCEWithLogitsLoss()__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "06dd6092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = HairClassifier()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf2f8e4",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What's the total number of parameters of the model? You can use torchsummary or count manually.\n",
    "\n",
    "__Answer: 20073473__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "753179ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20073473"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# manually find the parameter count\n",
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dbd6a5",
   "metadata": {},
   "source": [
    "### Actual training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f515228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6252, Acc: 0.6454, Val Loss: 0.7724, Val Acc: 0.5572\n",
      "Epoch 2/10, Loss: 0.5806, Acc: 0.6929, Val Loss: 0.6240, Val Acc: 0.6667\n",
      "Epoch 3/10, Loss: 0.5081, Acc: 0.7478, Val Loss: 0.7392, Val Acc: 0.6219\n",
      "Epoch 4/10, Loss: 0.5087, Acc: 0.7428, Val Loss: 0.6009, Val Acc: 0.7065\n",
      "Epoch 5/10, Loss: 0.4088, Acc: 0.8102, Val Loss: 0.6288, Val Acc: 0.6816\n",
      "Epoch 6/10, Loss: 0.3397, Acc: 0.8539, Val Loss: 0.5748, Val Acc: 0.7214\n",
      "Epoch 7/10, Loss: 0.3321, Acc: 0.8539, Val Loss: 0.6813, Val Acc: 0.6915\n",
      "Epoch 8/10, Loss: 0.2222, Acc: 0.9363, Val Loss: 0.6071, Val Acc: 0.7512\n",
      "Epoch 9/10, Loss: 0.1674, Acc: 0.9401, Val Loss: 0.6133, Val Acc: 0.7463\n",
      "Epoch 10/10, Loss: 0.1704, Acc: 0.9401, Val Loss: 0.9001, Val Acc: 0.6866\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_model():\n",
    "    num_epochs = 10\n",
    "    history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.float().unsqueeze(1) # Ensure labels are float and have shape (batch_size, 1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            # For binary classification with BCEWithLogitsLoss, apply sigmoid to outputs before thresholding for accuracy\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_ds)\n",
    "        epoch_acc = correct_train / total_train\n",
    "        history['loss'].append(epoch_loss)\n",
    "        history['acc'].append(epoch_acc)\n",
    "\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                labels = labels.float().unsqueeze(1)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_running_loss += loss.item() * images.size(0)\n",
    "                predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "        val_epoch_loss = val_running_loss / len(val_ds)\n",
    "        val_epoch_acc = correct_val / total_val\n",
    "        history['val_loss'].append(val_epoch_loss)\n",
    "        history['val_acc'].append(val_epoch_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "            f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
    "            f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")\n",
    "        \n",
    "        return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b2e267",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "What is the median of training accuracy for all the epochs for this model?\n",
    "\n",
    "__A: 0.84__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "eacb5f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8320848938826466)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(history['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16204339",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "What is the standard deviation of training loss for all the epochs for this model?\n",
    "\n",
    "__A: 0.171__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a2eb5725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.15865462466781946)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd2838",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Perform data augmentation and run the model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "61e129f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the initial input is of size (200, 200, 3)\n",
    "input_size=200\n",
    "\n",
    "# imagenet normalization values\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Simple transforms: (1) Resize the input (2) convert to a tensor (3) Normalize the image\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(input_size, input_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "    transforms.RandomRotation(50),\n",
    "    transforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(input_size, input_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "    transforms.RandomRotation(50),\n",
    "    transforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
    "    transforms.RandomHorizontalFlip()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "819b9b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.1683, Acc: 0.9351, Val Loss: 0.7072, Val Acc: 0.7562\n",
      "Epoch 2/10, Loss: 0.0987, Acc: 0.9663, Val Loss: 0.6710, Val Acc: 0.7562\n",
      "Epoch 3/10, Loss: 0.0377, Acc: 0.9975, Val Loss: 0.7331, Val Acc: 0.7612\n",
      "Epoch 4/10, Loss: 0.0396, Acc: 0.9900, Val Loss: 0.8554, Val Acc: 0.7413\n",
      "Epoch 5/10, Loss: 0.0146, Acc: 1.0000, Val Loss: 0.8343, Val Acc: 0.7512\n",
      "Epoch 6/10, Loss: 0.0099, Acc: 1.0000, Val Loss: 0.9009, Val Acc: 0.7512\n",
      "Epoch 7/10, Loss: 0.0078, Acc: 1.0000, Val Loss: 0.9656, Val Acc: 0.7512\n",
      "Epoch 8/10, Loss: 0.0064, Acc: 1.0000, Val Loss: 0.9055, Val Acc: 0.7313\n",
      "Epoch 9/10, Loss: 0.0056, Acc: 1.0000, Val Loss: 0.9821, Val Acc: 0.7512\n",
      "Epoch 10/10, Loss: 0.0046, Acc: 1.0000, Val Loss: 1.0000, Val Acc: 0.7512\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        labels = labels.float().unsqueeze(1) # Ensure labels are float and have shape (batch_size, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        # For binary classification with BCEWithLogitsLoss, apply sigmoid to outputs before thresholding for accuracy\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_ds)\n",
    "    epoch_acc = correct_train / total_train\n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['acc'].append(epoch_acc)\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_epoch_loss = val_running_loss / len(val_ds)\n",
    "    val_epoch_acc = correct_val / total_val\n",
    "    history['val_loss'].append(val_epoch_loss)\n",
    "    history['val_acc'].append(val_epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
    "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2987eeb",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Let's train our model for 10 more epochs using the same code as previously.\n",
    "\n",
    "Note: make sure you don't re-create the model. we want to continue training the model we already started training.\n",
    "What is the mean of test loss for all the epochs for the model trained with augmentations?\n",
    "\n",
    "__A: 0.88__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "88b4fab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8781717992688886)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c364ca2",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "What's the average of test accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations?\n",
    "\n",
    "__A: 0.68__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bad531c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7472636815920398)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(history['val_acc'][5:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-zoomcamp-1E68eU6L",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
